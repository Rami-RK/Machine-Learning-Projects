### Machine Learning Projects Based on Real DataSets

#### These are a few deliberately & specially selected projects which involve a lot of unique concepts, Feature engineering, rather than just train, fit, and test on simple data set.
#### Project 1. Credit Card Fraud Detection (Imbalanced Classification):
An example of imbalance classification and involves almost all the concepts required for handling imbalanced data. Concepts covered:
1) Scaling the data.
2) Suitable performance metric for testing the accuracy of imbalanced data. --> Confusion Matrix, Precision, Recall, ROC, AUC
3) Techniques for imbalanced data. --> Oversampling of the minority class, Undersampling of the minority class, Synthetic Minority Oversampling Technique (SMOTE)
4) Tried Different Algorithms for modeling & accuracy are compared.
#### Project 2. Loan Amount Prediction: 
A regression problem where we have to predict the loan amount based on 20 features. The feature contains both Numerical and categorical data. Concepts covered:
1) Replacing NULL in categorical columns.
2) Use one-hot encoding ( low cardinality ) and frequency encoding (high cardinality)
3) Outlier removal using IQR.
4) Testing skewness of output and log transformation for normalization of data.
5) Correlation comparison between features
5) Checking and removal of Multicollinearity using VIF technique
6) Modelling and accuracy testing 
#### Project 3. Naive Bayes for Text Classification:
An application of  Naive Bayes, for text classification Where everything explained from scratch accompanied with a slide(Text Classification Naive Bayes.pptx) for an explanation of equations and compared with the sckit-learn result. Concept covered:
1) Removing stopwords
2) Building a vocabulary of words
3) Frequency calculation of words
4) Vectorising the text data set
5) Making our function for train and predict 
6) Classifying a text given by the user
7) Confusion matrix for the performance of the model
#### Project 4. Housing Price prediction:
A regression problem for which Linear Regression, Decision Tree Regressor, Random forest Regressor, Support Vector Regressor are applied and best one is selected.
Concepts covered:
1) pd.get_dummies --> for easy implementation of  one hot encoding
2) Imputation
2) Few interesting data visualization and physical interpretation
3) Standard Scalar
4) Cross validation score
5) Grid Search and Randomized Grid Search for fine tuning the model
